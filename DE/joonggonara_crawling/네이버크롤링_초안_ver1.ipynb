{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "990920572\n",
      "990920541\n",
      "990920538\n",
      "990920507\n",
      "990920409\n",
      "990920320\n",
      "990920139\n",
      "990920109\n",
      "990920026\n",
      "990919913\n",
      "990919881\n",
      "990919879\n",
      "990919809\n",
      "990919770\n",
      "990919620\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# WebDriver 경로 설정\n",
    "# path = \"path_to_chromedriver\"  # 여기에 실제 ChromeDriver 경로를 입력해주세요.\n",
    "\n",
    "# WebDriver 인스턴스 생성 (Chrome 브라우저)\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# 페이지 로드\n",
    "url = 'https://cafe.naver.com/joonggonara?iframe_url=/ArticleList.nhn%3Fsearch.clubid=10050146%26search.menuid=334%26search.boardtype=L%26search.totalCount=151%26search.cafeId=10050146%26search.page=1'\n",
    "driver.get(url)\n",
    "\n",
    "# 페이지가 완전히 로드될 때까지 대기\n",
    "time.sleep(5)\n",
    "\n",
    "# iframe으로 이동\n",
    "driver.switch_to.frame('cafe_main')\n",
    "\n",
    "# 페이지 소스를 가져옴\n",
    "html = driver.page_source\n",
    "\n",
    "# BeautifulSoup 객체 생성\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# inner_number 찾기\n",
    "inner_numbers = soup.find_all('div', {'class': 'inner_number'})\n",
    "\n",
    "# WebDriver 종료\n",
    "driver.quit()\n",
    "\n",
    "for inner_number in inner_numbers:\n",
    "    print(inner_number.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json\n",
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "def get_inner_numbers(page):\n",
    "    # WebDriver 경로 설정\n",
    "    # path = \"path_to_chromedriver\"  # 여기에 실제 ChromeDriver 경로를 입력\n",
    "\n",
    "    # WebDriver 인스턴스 생성 (Chrome 브라우저)\n",
    "    driver = webdriver.Chrome()\n",
    "\n",
    "    # 페이지 로드\n",
    "    url = f\"https://cafe.naver.com/joonggonara?iframe_url=/ArticleList.nhn%3Fsearch.clubid=10050146%26search.menuid=334%26search.boardtype=L%26search.totalCount=151%26search.cafeId=10050146%26search.page={page}\"\n",
    "    driver.get(url)\n",
    "\n",
    "    # 페이지가 완전히 로드될 때까지 대기\n",
    "    time.sleep(5)\n",
    "\n",
    "    # iframe으로 이동\n",
    "    driver.switch_to.frame('cafe_main')\n",
    "\n",
    "    # 페이지 소스를 가져옴\n",
    "    html = driver.page_source\n",
    "\n",
    "    # BeautifulSoup 객체 생성\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # inner_number 찾기\n",
    "    inner_numbers = soup.find_all('div', {'class': 'inner_number'})\n",
    "\n",
    "    # WebDriver 종료\n",
    "    driver.quit()\n",
    "\n",
    "    # inner_numbers를 텍스트로 변환하여 리스트로 반환\n",
    "    return [num.text.strip() for num in inner_numbers]\n",
    "\n",
    "def ju(page):\n",
    "    # API URL을 쉽게 바꿀 수 있도록 만든 base url\n",
    "    base_api_url = \"https://apis.naver.com/cafe-web/cafe-articleapi/v2.1/cafes/10050146/articles/{}?query=&menuId=334&boardType=L&useCafeId=true&requestFrom=A\"\n",
    "\n",
    "    # inner_number 가져오기\n",
    "    inner_numbers = get_inner_numbers(page)\n",
    "\n",
    "    # API를 사용하여 데이터 가져오기\n",
    "    data_list = []\n",
    "    for num in inner_numbers:\n",
    "        api_url = base_api_url.format(num)\n",
    "        api_res = requests.get(api_url)\n",
    "        api_data = api_res.json()  # API response to json\n",
    "\n",
    "        # 'result'가 존재하고 그 아래에 'article'이 존재하는지 확인\n",
    "        if 'result' in api_data and 'article' in api_data['result']:\n",
    "            # 원하는 데이터를 추출하고 이를 data_list에 추가\n",
    "            data = api_data['result']['article']  # JSON 구조에 따라 수정\n",
    "        else:\n",
    "            # 'article' 정보가 없는 경우에 대비해 빈 딕셔너리를 사용\n",
    "            data = {}\n",
    "        # inner_number를 추가하고, 없는 값에 대해서는 공백으로 처리\n",
    "        data_list.append({\n",
    "            'inner_number': num,\n",
    "            'articleId': data.get('id', ''),\n",
    "            'subject': data.get('subject', ''),\n",
    "            'writer_id': data.get('writer', {}).get('id', ''),\n",
    "            'writer_nick': data.get('writer', {}).get('nick', ''),\n",
    "            'memberLevelName': data.get('writer', {}).get('memberLevelName', ''),\n",
    "            'writeDate': data.get('writeDate', ''),\n",
    "            'readCount': data.get('readCount', ''),\n",
    "            'commentCount': data.get('commentCount', ''),\n",
    "        })\n",
    "\n",
    "    # 데이터프레임으로 변환 후 csv 파일로 저장\n",
    "    df = pd.DataFrame(data_list)\n",
    "    df.to_csv(\"data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "ju(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json\n",
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "def get_inner_numbers(page):\n",
    "    # WebDriver 경로 설정\n",
    "    # path = \"path_to_chromedriver\"  # 여기에 실제 ChromeDriver 경로를 입력\n",
    "\n",
    "    # WebDriver 인스턴스 생성 (Chrome 브라우저)\n",
    "    driver = webdriver.Chrome()\n",
    "\n",
    "    # 페이지 로드\n",
    "    url = f\"https://cafe.naver.com/joonggonara?iframe_url=/ArticleList.nhn%3Fsearch.clubid=10050146%26search.menuid=334%26search.boardtype=L%26search.totalCount=151%26search.cafeId=10050146%26search.page={page}\"\n",
    "    driver.get(url)\n",
    "\n",
    "    # 페이지가 완전히 로드될 때까지 대기\n",
    "    time.sleep(5)\n",
    "\n",
    "    # iframe으로 이동\n",
    "    driver.switch_to.frame('cafe_main')\n",
    "\n",
    "    # 페이지 소스를 가져옴\n",
    "    html = driver.page_source\n",
    "\n",
    "    # BeautifulSoup 객체 생성\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # inner_number 찾기\n",
    "    inner_numbers = soup.find_all('div', {'class': 'inner_number'})\n",
    "\n",
    "    # WebDriver 종료\n",
    "    driver.quit()\n",
    "\n",
    "    # inner_numbers를 텍스트로 변환하여 리스트로 반환\n",
    "    return [num.text.strip() for num in inner_numbers]\n",
    "\n",
    "def ju(inner_numbers):\n",
    "    # API URL을 쉽게 바꿀 수 있도록 만든 base url\n",
    "    base_api_url = \"https://apis.naver.com/cafe-web/cafe-articleapi/v2.1/cafes/10050146/articles/{}?query=&menuId=334&boardType=L&useCafeId=true&requestFrom=A\"\n",
    "\n",
    "    # API를 사용하여 데이터 가져오기\n",
    "    data_list = []\n",
    "    for num in inner_numbers:\n",
    "        api_url = base_api_url.format(num)\n",
    "        api_res = requests.get(api_url)\n",
    "        api_data = api_res.json()  # API response to json\n",
    "\n",
    "        # 'result'가 존재하고 그 아래에 'article'이 존재하는지 확인\n",
    "        if 'result' in api_data and 'article' in api_data['result']:\n",
    "            # 원하는 데이터를 추출하고 이를 data_list에 추가\n",
    "            data = api_data['result']['article']  # JSON 구조에 따라 수정\n",
    "        else:\n",
    "            # 'article' 정보가 없는 경우에 대비해 빈 딕셔너리를 사용\n",
    "            data = {}\n",
    "        # inner_number를 추가하고, 없는 값에 대해서는 공백으로 처리\n",
    "        data_list.append({\n",
    "            'inner_number': num,\n",
    "            'articleId': data.get('id', ''),\n",
    "            'subject': data.get('subject', ''),\n",
    "            'writer_id': data.get('writer', {}).get('id', ''),\n",
    "            'writer_nick': data.get('writer', {}).get('nick', ''),\n",
    "            'memberLevelName': data.get('writer', {}).get('memberLevelName', ''),\n",
    "            'writeDate': data.get('writeDate', ''),\n",
    "            'readCount': data.get('readCount', ''),\n",
    "            'commentCount': data.get('commentCount', ''),\n",
    "        })\n",
    "\n",
    "    # 데이터프레임으로 변환 후 csv 파일로 저장\n",
    "    df = pd.DataFrame(data_list)\n",
    "    df.to_csv(\"data.csv\", index=False)\n",
    "\n",
    "# 여러 페이지의 데이터 가져오기\n",
    "start_page = 1\n",
    "end_page = 5  # 마지막 페이지 번호 설정\n",
    "\n",
    "all_inner_numbers = []\n",
    "for page in range(start_page, end_page+1):\n",
    "    inner_numbers = get_inner_numbers(page)\n",
    "    all_inner_numbers.extend(inner_numbers)\n",
    "\n",
    "# API 정보 가져오기\n",
    "ju(all_inner_numbers)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataengineer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
